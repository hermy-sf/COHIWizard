            self.SigAnnSpectrum.emit(data)
            #print("sleep before continue 1")
            while self.get_continue() == False:
                time.sleep(0.001)
            self.SigAnnSpectrum.emit(data)  #????????????????TODO check
            pdata = self.get_pdata()
            self.set_continue(False)
            #optional plotting if activated
            self.SigPlotdata.emit()
            # wait until plot has been carried out
            #print("sleep before continue 2")
            while self.get_continue() == False:
                time.sleep(0.001)
            self.annot[self.autoscan_ix]["FREQ"] = pdata["datax"] 
            self.annot[self.autoscan_ix]["PKS"] = pdata["peaklocs"]
            peaklocs = pdata["peaklocs"]
            datay = pdata["datay"]
            basel = pdata["databasel"] + self.get_baselineoffset()
            self.annot[self.autoscan_ix]["SNR"] = datay[peaklocs] - basel[peaklocs]
            self.annot[self.autoscan_ix]["PEAKVALS"] = datay[peaklocs]
            #print(f'asf: peaklocs: {peaklocs}')
            #print(f'asf: basel   : {basel[peaklocs]}')
            #print(f'asf: SNR     : {datay[peaklocs] - basel[peaklocs]}')
            #collect all peaks which have occurred at least once in an array
            self.peakvals_union = np.union1d(self.peakvals_union, self.annot[self.autoscan_ix]["PEAKVALS"])
            self.locs_union = np.union1d(self.locs_union, self.annot[self.autoscan_ix]["PKS"])
            self.freq_union = np.union1d(self.freq_union, self.annot[self.autoscan_ix]["FREQ"][self.annot[self.autoscan_ix]["PKS"]])
        # purge self.locs.union and remove elements the frequencies of which are
        # within 1 kHz span 
        uniquefreqs = pd.unique(np.round(self.freq_union/1000))
        xyi, x_ix, y_ix = np.intersect1d(uniquefreqs, np.round(self.freq_union/1000), return_indices=True)

        self.locs_union= self.locs_union[y_ix]
        self.freq_union = self.freq_union[y_ix]
        self.peakvals_union = self.peakvals_union[y_ix]
        self.set_unions([self.locs_union,self.freq_union, self.peakvals_union])
        self.SigUpdateUnions.emit()

        meansnr = np.zeros(len(self.locs_union))
        meanpeakval = np.zeros(len(self.locs_union))
        minsnr = 1000*np.ones(len(self.locs_union))
        maxsnr = -1000*np.ones(len(self.locs_union))
        reannot = {}
        datasnaps = []
        for ix in range(self.NUMSNAPS):
            # find indices of current LOCS in the unified LOC vector self.locs_union
            sharedvals, ix_un, ix_ann = np.intersect1d(self.locs_union, self.annot[ix]["PKS"], return_indices=True)
            # write current SNR to the corresponding places of the self.reannotated matrix
            reannot["SNR"] = np.zeros(len(self.locs_union))
            reannot["SNR"][ix_un] = self.annot[ix]["SNR"][ix_ann]
            reannot["PEAKVALS"] = np.zeros(len(self.locs_union))
            reannot["PEAKVALS"][ix_un] = self.annot[ix]["PEAKVALS"][ix_ann]
            datasnaps.append(reannot["PEAKVALS"])
            #Global Statistics, without consideration whether some peaks vanish or
            #appear when running through all values of ix
            meansnr = meansnr + reannot["SNR"]
            meanpeakval = meanpeakval + reannot["PEAKVALS"]
            #min and max SNR data are currently not being used.
            minsnr = np.minimum(minsnr, reannot["SNR"])
            maxsnr = np.maximum(maxsnr, reannot["SNR"])
            #print("annotate worker findpeak")
        self.set_datasnaps(datasnaps)
        # collect cumulative info in a dictionary and write the info to the annotation yaml file 
        self.annotation = {}
        self.annotation["MSNR"] = meansnr/self.NUMSNAPS
        self.annotation["PEAKVALS"] = meanpeakval/self.NUMSNAPS
        self.annotation["FREQ"] = np.round(self.freq_union/1000) # signifikante Stellen
